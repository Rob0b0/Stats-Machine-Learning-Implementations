{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from struct import unpack\n",
    "import gzip\n",
    "from numpy import zeros, uint8, float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for parsing in dataset\n",
    "def get_labeled_data(imagefile, labelfile):\n",
    "    \"\"\"Read input-vector (image) and target class (label, 0-9) and return\n",
    "       it as list of tuples.\n",
    "    \"\"\"\n",
    "    # Open the images with gzip in read binary mode\n",
    "    images = gzip.open(imagefile, 'rb')\n",
    "    labels = gzip.open(labelfile, 'rb')\n",
    "\n",
    "    # Read the binary data\n",
    "\n",
    "    # We have to get big endian unsigned int. So we need '>I'\n",
    "\n",
    "    # Get metadata for images\n",
    "    images.read(4)  # skip the magic_number\n",
    "    number_of_images = images.read(4)\n",
    "    number_of_images = unpack('>I', number_of_images)[0]\n",
    "    rows = images.read(4)\n",
    "    rows = unpack('>I', rows)[0]\n",
    "    cols = images.read(4)\n",
    "    cols = unpack('>I', cols)[0]\n",
    "\n",
    "    # Get metadata for labels\n",
    "    labels.read(4)  # skip the magic_number\n",
    "    N = labels.read(4)\n",
    "    N = unpack('>I', N)[0]\n",
    "\n",
    "    if number_of_images != N:\n",
    "        raise Exception('number of labels did not match the number of images')\n",
    "\n",
    "    # Get the data\n",
    "    x = zeros((N, rows, cols), dtype=float32)  # Initialize numpy array\n",
    "    y = zeros((N, 1), dtype=uint8)  # Initialize numpy array\n",
    "    for i in range(N):\n",
    "        if i % 1000 == 0:\n",
    "            print(\"i: %i\" % i)\n",
    "        for row in range(rows):\n",
    "            for col in range(cols):\n",
    "                tmp_pixel = images.read(1)  # Just a single byte\n",
    "                tmp_pixel = unpack('>B', tmp_pixel)[0]\n",
    "                x[i][row][col] = tmp_pixel\n",
    "        tmp_label = labels.read(1)\n",
    "        y[i] = unpack('>B', tmp_label)[0]\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pylab import imshow, show, cm\n",
    "\n",
    "# Function for viewing images\n",
    "def view_image(image, label=\"\"):\n",
    "    \"\"\"View a single image.\"\"\"\n",
    "    print(\"Label: %s\" % label)\n",
    "    imshow(image, cmap=cm.gray)\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "i: 1000\n",
      "i: 2000\n",
      "i: 3000\n",
      "i: 4000\n",
      "i: 5000\n",
      "i: 6000\n",
      "i: 7000\n",
      "i: 8000\n",
      "i: 9000\n",
      "i: 10000\n",
      "i: 11000\n",
      "i: 12000\n",
      "i: 13000\n",
      "i: 14000\n",
      "i: 15000\n",
      "i: 16000\n",
      "i: 17000\n",
      "i: 18000\n",
      "i: 19000\n",
      "i: 20000\n",
      "i: 21000\n",
      "i: 22000\n",
      "i: 23000\n",
      "i: 24000\n",
      "i: 25000\n",
      "i: 26000\n",
      "i: 27000\n",
      "i: 28000\n",
      "i: 29000\n",
      "i: 30000\n",
      "i: 31000\n",
      "i: 32000\n",
      "i: 33000\n",
      "i: 34000\n",
      "i: 35000\n",
      "i: 36000\n",
      "i: 37000\n",
      "i: 38000\n",
      "i: 39000\n",
      "i: 40000\n",
      "i: 41000\n",
      "i: 42000\n",
      "i: 43000\n",
      "i: 44000\n",
      "i: 45000\n",
      "i: 46000\n",
      "i: 47000\n",
      "i: 48000\n",
      "i: 49000\n",
      "i: 50000\n",
      "i: 51000\n",
      "i: 52000\n",
      "i: 53000\n",
      "i: 54000\n",
      "i: 55000\n",
      "i: 56000\n",
      "i: 57000\n",
      "i: 58000\n",
      "i: 59000\n",
      "i: 0\n",
      "i: 1000\n",
      "i: 2000\n",
      "i: 3000\n",
      "i: 4000\n",
      "i: 5000\n",
      "i: 6000\n",
      "i: 7000\n",
      "i: 8000\n",
      "i: 9000\n"
     ]
    }
   ],
   "source": [
    "# training set\n",
    "training_set = get_labeled_data(\"train-images-idx3-ubyte.gz\", \"train-labels-idx1-ubyte.gz\")\n",
    "testing_set = get_labeled_data(\"t10k-images-idx3-ubyte.gz\", \"t10k-labels-idx1-ubyte.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: [5]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQknxGq+fLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10d06b780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test two functions\n",
    "training_set[0].shape\n",
    "view_image(training_set[0][1],training_set[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    3.   18.   18.   18.\n",
      "  126.  136.  175.   26.  166.  255.  247.  127.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.   30.   36.   94.  154.\n",
      "  170.  253.  253.  253.  253.  253.  225.  172.  253.  242.  195.   64.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   49.\n",
      "  238.  253.  253.  253.  253.  253.  253.  253.  253.  251.   93.   82.\n",
      "   82.   56.   39.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.   18.  219.  253.  253.  253.  253.  253.  198.  182.\n",
      "  247.  241.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.   80.  156.  107.  253.\n",
      "  253.  205.   11.    0.   43.  154.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.   14.    1.  154.  253.   90.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.  139.  253.  190.    2.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   11.\n",
      "  190.  253.   70.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.   35.  241.  225.  160.  108.    1.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.   81.  240.  253.\n",
      "  253.  119.   25.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.   45.  186.  253.  253.  150.   27.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.   16.   93.  252.  253.  187.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.  249.  253.  249.   64.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.   46.  130.  183.  253.  253.  207.    2.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.   39.  148.  229.  253.  253.  253.  250.  182.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.   24.  114.  221.  253.  253.  253.\n",
      "  253.  201.   78.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.   23.   66.  213.  253.\n",
      "  253.  253.  253.  198.   81.    2.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   18.  171.\n",
      "  219.  253.  253.  253.  253.  195.   80.    9.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "   55.  172.  226.  253.  253.  253.  253.  244.  133.   11.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.  136.  253.  253.  253.  212.  135.  132.   16.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.]\n",
      "oldie:::::::::\n",
      "[[   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     3.   18.   18.   18.  126.  136.  175.   26.  166.  255.  247.  127.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.   30.   36.   94.  154.\n",
      "   170.  253.  253.  253.  253.  253.  225.  172.  253.  242.  195.   64.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.   49.  238.  253.  253.  253.\n",
      "   253.  253.  253.  253.  253.  251.   93.   82.   82.   56.   39.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.   18.  219.  253.  253.  253.\n",
      "   253.  253.  198.  182.  247.  241.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.   80.  156.  107.  253.\n",
      "   253.  205.   11.    0.   43.  154.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.   14.    1.  154.\n",
      "   253.   90.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  139.\n",
      "   253.  190.    2.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   11.\n",
      "   190.  253.   70.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    35.  241.  225.  160.  108.    1.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.   81.  240.  253.  253.  119.   25.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.   45.  186.  253.  253.  150.   27.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.   16.   93.  252.  253.  187.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.  249.  253.  249.   64.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.   46.  130.  183.  253.  253.  207.    2.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    39.  148.  229.  253.  253.  253.  250.  182.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   24.  114.\n",
      "   221.  253.  253.  253.  253.  201.   78.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.   23.   66.  213.  253.\n",
      "   253.  253.  253.  198.   81.    2.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.   18.  171.  219.  253.  253.  253.\n",
      "   253.  195.   80.    9.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.   55.  172.  226.  253.  253.  253.  253.  244.\n",
      "   133.   11.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.  136.  253.  253.  253.  212.  135.  132.   16.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]\n",
      " [   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# reshape the 28x28 image data\n",
    "\n",
    "training_img = np.reshape(training_set[0], (60000, 784))\n",
    "print(training_img[0])\n",
    "print(\"oldie:::::::::\")\n",
    "print(training_set[0][0])\n",
    "\n",
    "# new training set after reshape\n",
    "training_reshaped = (training_img, training_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a validation set of 1000\n",
    "valid_size = 1000\n",
    "training = (training_reshaped[0][: -valid_size], training_reshaped[1][: -valid_size])\n",
    "validation = (training_reshaped[0][-valid_size:], training_reshaped[1][-valid_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 0, 9: 0}\n",
      "{0: 5825, 1: 6640, 2: 5853, 3: 6028, 4: 5746, 5: 5331, 6: 5811, 7: 6158, 8: 5757, 9: 5851}\n",
      "10\n",
      "(5825, 784)\n",
      "(6640, 784)\n",
      "(5853, 784)\n",
      "(6028, 784)\n",
      "(5746, 784)\n",
      "(5331, 784)\n",
      "(5811, 784)\n",
      "(6158, 784)\n",
      "(5757, 784)\n",
      "(5851, 784)\n"
     ]
    }
   ],
   "source": [
    "# create dictionary for recording size of each label\n",
    "dict_size={}\n",
    "for i in range(10):\n",
    "    dict_size[i]=0\n",
    "print(dict_size)\n",
    "\n",
    "# get data size of each label\n",
    "for label in np.nditer(training[1]):\n",
    "    dict_size[int(label)]=dict_size[int(label)]+1\n",
    "print(dict_size)\n",
    "\n",
    "# create a list of 10 nparrays in order of label\n",
    "ordered_train = {}\n",
    "for i in range(10):\n",
    "    ordered_train[i]=np.empty((0,784),float32)\n",
    "print (len(ordered_train))\n",
    "for img,label in zip(training[0], training[1]):\n",
    "    ordered_train[label[0]] = np.append(ordered_train[label[0]],np.array([img]), axis=0)\n",
    "        \n",
    "for t in ordered_train:\n",
    "    print(ordered_train[t].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 784)\n",
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "cov_matrix_dict = {}\n",
    "mean_dict = {}\n",
    "\n",
    "# tuning this parameter\n",
    "c=0.4\n",
    "\n",
    "# start calculating mean and covariance matrix\n",
    "for class_id, ts in ordered_train.items():\n",
    "    # print(ts[255])\n",
    "    cov_matrix = np.cov(ts, rowvar=False)\n",
    "    # mean = np.mean(ts, axis=0)\n",
    "    mean = np.array(ts.mean(0))\n",
    "    # smooth cov matrix\n",
    "    cov_matrix = cov_matrix + c * np.identity(784)\n",
    "    cov_matrix_dict[class_id] = cov_matrix\n",
    "    mean_dict[class_id] = mean\n",
    "\n",
    "print(cov_matrix_dict[0].shape)\n",
    "print(mean_dict[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-58631957.0242\n",
      "-57987953.5449\n",
      "-48401898.7498\n",
      "-45037393.7796\n",
      "-47616097.785\n",
      "-40673204.0509\n",
      "-75185642.1106\n",
      "-30215883.625\n",
      "-51274911.6426\n",
      "-34919920.172\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "p_dict = {}\n",
    "# calculate p\n",
    "for i in range(0, 10):\n",
    "    mean = mean_dict[i]\n",
    "    cov = cov_matrix_dict[i]\n",
    "    #print(\"mean.shape: \"+ str(mean.shape))\n",
    "    #print(\"mean value: \" + str(mean[663]))\n",
    "    #print(\"cov.shape: \"+ str(cov.shape))\n",
    "    p_dict[i]= multivariate_normal(mean=mean, cov=cov, allow_singular=False)\n",
    "\n",
    "# x = np.random.rand(1,784)\n",
    "x = np.linspace(0.0, 783, num=784)\n",
    "# print(\"cov value: \" + str(cov_matrix_dict[5][620][249]))\n",
    "# print(\"mean value: \" + str(mean_dict[5][220]))\n",
    "# print(multivariate_normal.logpdf(x, mean=mean_dict[5], cov=cov_matrix_dict[5])) # number too small \n",
    "\n",
    "for i in p_dict:\n",
    "    print(p_dict[i].logpdf(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.09872881355932203, 1: 0.11254237288135593, 2: 0.09920338983050847, 3: 0.10216949152542373, 4: 0.09738983050847458, 5: 0.09035593220338983, 6: 0.09849152542372881, 7: 0.1043728813559322, 8: 0.09757627118644067, 9: 0.09916949152542373}\n"
     ]
    }
   ],
   "source": [
    "# calculate prior\n",
    "prior_dict = {}\n",
    "for i,size in dict_size.items():\n",
    "    prior_dict[i] = dict_size[i]/(60000-valid_size)\n",
    "print (prior_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training in validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.249\n"
     ]
    }
   ],
   "source": [
    "# for img, label in zip(validation[0], validation[1]):\n",
    "correct_num = 0\n",
    "for m in range(0, 999):\n",
    "    img = validation[0][m]\n",
    "    label = validation[1][m]\n",
    "    bayes_prob = []\n",
    "    # try each Pr\n",
    "    for i in range(10):\n",
    "        # print (p_dict[i].logpdf(img))\n",
    "        prob = [i, prior_dict[i]*(p_dict[i].logpdf(img))]\n",
    "        bayes_prob.append(prob)\n",
    "    # print (bayes_prob)\n",
    "    the_one = 0\n",
    "    the_max = -9999999999\n",
    "    for i in range(0, 9):\n",
    "        if(bayes_prob[i][1] > the_max):\n",
    "            the_max = bayes_prob[i][1]\n",
    "            the_one = bayes_prob[i][0]\n",
    "        \n",
    "    #print (\"Correct Label is \" + str(label) + \" Our guess is \" + str(the_one))\n",
    "    if(label == the_one):\n",
    "        correct_num += 1\n",
    "print(1 - correct_num/1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
